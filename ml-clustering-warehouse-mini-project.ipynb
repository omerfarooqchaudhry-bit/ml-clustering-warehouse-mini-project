{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1957553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Wholesales\n",
    "Let's Do the Mini Project\n",
    "Description\n",
    "Wholesale distributors can get all kinds of insights into enhancing their business by analyzing their customers' data. Try a simple clustering analysis!\n",
    "License: The dataset is CC0: Public Domain, and it is publicly available in the UCI Machine Learning Repository.\n",
    "You will need to use GitHub to complete this Mini Project. Find Guidelines for Using GitHub here.\n",
    "Expected Output\n",
    "By the end of this Mini Project, you should deliver within your code:\n",
    "Multiple Dunn Index measures resembling different k used for K-Means clustering your data.\n",
    "An output plot of the elbow curve.\n",
    "The best k chosen based on the elbow curve plot.\n",
    "Output predicted clusters for the first 10 data samples.\n",
    "\"\"\"\n",
    "def main():\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.calibration import LabelEncoder\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    # STEP 1: Download the Dataset\n",
    "    # STEP 2: Reading the Dataset. Does the dataset include any missing values? If so, drop them!\n",
    "    df = pd.read_csv('Wholesale customers data.csv')\n",
    "    print(\"TYPE\", type(df))\n",
    "    print(\"DATASET\", df)\n",
    "    print(\"DATASET INFO\", df.info())\n",
    "\n",
    "    \"\"\"missing values elimination is optional. don't have to have acomplete row because we are not passing arrays. it can pass over missing values\"\"\"\n",
    "    missing_mask = df.isna()\n",
    "    print(\"BOOLEAN MISSING VALUE MASK:\")\n",
    "    print(missing_mask.head())  # Shows True where data is missing\n",
    "\n",
    "    # Step 2b: Count total missing values per column\n",
    "    missing_counts = missing_mask.sum()\n",
    "    print(\"\\nCOUNT OF MISSING VALUES PER COLUMN:\")\n",
    "    print(missing_counts)\n",
    "\n",
    "    # Step 2c: Count total missing values in entire dataset\n",
    "    total_missing = missing_mask.values.sum()\n",
    "    print(\"\\nTOTAL MISSING VALUES IN DATASET:\", total_missing)\n",
    "\n",
    "    \"\"\"\n",
    "    no missing valus found\n",
    "    \"\"\"\n",
    "\n",
    "    print('SHAPE', df.shape)\n",
    "    print(\"NUMBER OF TUPLES\",(df.shape)[0])\n",
    "\n",
    "\n",
    "    # 2. Feature Selection and Preparation\n",
    "# One-hot encode 'Channel' and 'Region' to make them meaningfully impact the analysis\n",
    "    df = pd.get_dummies(df, columns=['Channel', 'Region'], dtype = int, drop_first=False)\n",
    "\n",
    "    print(\"ENCODED\", df.head())\n",
    "\n",
    "    # The features to scale are all columns in df_processed\n",
    "    X = df\n",
    "\n",
    "# 3. Preprocessing (Scaling)\n",
    "# Scaling all features is generally a good practice for K-Means\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"SCALED\", X_scaled)\n",
    "    print(\"SCALED TYPE\", type(X_scaled))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Clustering Using K-Means\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Use a K-Means instance to cluster the data.\n",
    "\n",
    "\n",
    "    # Create the model with a number that might make sense based on the visualization\n",
    "    from sklearn.cluster import KMeans\n",
    "    model = KMeans(n_clusters = 5, random_state=0)\n",
    "\n",
    "    # What are we predicting with this model?\n",
    "    # The number used to count off which objects belong in the same group!\n",
    "\n",
    "    y = model.fit_predict(X_scaled)\n",
    "    print(\"y\", y)   \n",
    "\n",
    "    # Determine the Centroids for visualization\n",
    "    # (The output is the set of coordinates that we can use to visualize the centroid.)\n",
    "\n",
    "    centres = model.cluster_centers_\n",
    "    print(\"centres...\", centres) \n",
    "\n",
    "    # 2. Choose different values of k for the K-means algorithm.\n",
    "    from sklearn.cluster import KMeans\n",
    "    scores = []\n",
    "    for i in range(1, 11):\n",
    "        model = KMeans(n_clusters=i, random_state=0)\n",
    "        model.fit(X_scaled)\n",
    "        scores.append(model.inertia_)\n",
    "        print (\"scores\", scores)\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(range(1, 11), scores, marker='.', markersize=10)\n",
    "    plt.title('The Elbow Method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Inertia') # Model Inertia\n",
    "    \n",
    "main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
